{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from smote.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>927.89</td>\n",
       "      <td>0.04</td>\n",
       "      <td>23.04</td>\n",
       "      <td>40.27</td>\n",
       "      <td>21378.61</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>769.78</td>\n",
       "      <td>0.07</td>\n",
       "      <td>14.86</td>\n",
       "      <td>51.81</td>\n",
       "      <td>11436.73</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>254.75</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.35</td>\n",
       "      <td>27.25</td>\n",
       "      <td>2381.95</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>175.69</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6.82</td>\n",
       "      <td>25.77</td>\n",
       "      <td>1197.90</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>278.63</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9.69</td>\n",
       "      <td>28.75</td>\n",
       "      <td>2700.58</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.50</td>\n",
       "      <td>5.33</td>\n",
       "      <td>12.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.94</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4.00</td>\n",
       "      <td>15.24</td>\n",
       "      <td>243.78</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>102.80</td>\n",
       "      <td>0.17</td>\n",
       "      <td>6.00</td>\n",
       "      <td>17.13</td>\n",
       "      <td>616.79</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2109 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loc  v(g)  ev(g)  iv(g)      n       v     l      d      i         e  \\\n",
       "0      1.1   1.4    1.4    1.4    1.3    1.30  1.30   1.30   1.30      1.30   \n",
       "1      1.0   1.0    1.0    1.0    1.0    1.00  1.00   1.00   1.00      1.00   \n",
       "2     83.0  11.0    1.0   11.0  171.0  927.89  0.04  23.04  40.27  21378.61   \n",
       "3     46.0   8.0    6.0    8.0  141.0  769.78  0.07  14.86  51.81  11436.73   \n",
       "4     25.0   3.0    1.0    3.0   58.0  254.75  0.11   9.35  27.25   2381.95   \n",
       "...    ...   ...    ...    ...    ...     ...   ...    ...    ...       ...   \n",
       "2104  19.0   2.0    1.0    2.0   40.0  175.69  0.15   6.82  25.77   1197.90   \n",
       "2105  23.0   3.0    3.0    3.0   60.0  278.63  0.10   9.69  28.75   2700.58   \n",
       "2106   2.0   1.0    1.0    1.0    4.0    8.00  0.67   1.50   5.33     12.00   \n",
       "2107  13.0   1.0    1.0    1.0   17.0   60.94  0.25   4.00  15.24    243.78   \n",
       "2108  11.0   2.0    1.0    2.0   27.0  102.80  0.17   6.00  17.13    616.79   \n",
       "\n",
       "      ...  lOCode  lOComment  lOBlank  locCodeAndComment  uniq_Op  uniq_Opnd  \\\n",
       "0     ...       2          2        2                  2      1.2        1.2   \n",
       "1     ...       1          1        1                  1      1.0        1.0   \n",
       "2     ...      65         10        6                  0     18.0       25.0   \n",
       "3     ...      37          2        5                  0     16.0       28.0   \n",
       "4     ...      21          0        2                  0     11.0       10.0   \n",
       "...   ...     ...        ...      ...                ...      ...        ...   \n",
       "2104  ...      12          1        2                  0     10.0       11.0   \n",
       "2105  ...      18          1        2                  0     12.0       13.0   \n",
       "2106  ...       0          0        0                  0      3.0        1.0   \n",
       "2107  ...       6          0        5                  0      6.0        6.0   \n",
       "2108  ...       9          0        0                  0      8.0        6.0   \n",
       "\n",
       "      total_Op  total_Opnd  branchCount  class  \n",
       "0          1.2         1.2          1.4  False  \n",
       "1          1.0         1.0          1.0   True  \n",
       "2        107.0        64.0         21.0   True  \n",
       "3         89.0        52.0         15.0   True  \n",
       "4         41.0        17.0          5.0   True  \n",
       "...        ...         ...          ...    ...  \n",
       "2104      25.0        15.0          3.0  False  \n",
       "2105      39.0        21.0          5.0  False  \n",
       "2106       3.0         1.0          1.0  False  \n",
       "2107       9.0         8.0          1.0  False  \n",
       "2108      18.0         9.0          3.0  False  \n",
       "\n",
       "[2109 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"KC1.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.loc[[1013, 256, 6, 576, 773, 2104, 500, 131, 2100,1451,1450,1500,2]]\n",
    "# data_sample[['loc','v(g)','class']].loc[data_sample['class'] == True] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>55.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loc  v(g)  class\n",
       "256  55.0   5.0   True\n",
       "6    48.0   6.0   True\n",
       "131  47.0   4.0   True\n",
       "2    83.0  11.0   True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample[['loc','v(g)','class']].loc[data_sample['class'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>8.062258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>7.071068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.236068</td>\n",
       "      <td>8.062258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.635642</td>\n",
       "      <td>35.355339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0          1          2\n",
       "0  0.0   7.071068   8.062258\n",
       "1  0.0   2.236068   7.071068\n",
       "2  0.0   2.236068   8.062258\n",
       "3  0.0  28.635642  35.355339"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "neigh = NearestNeighbors(n_neighbors=3)\n",
    "neigh.fit(data_sample[['loc','v(g)','class']].loc[data_sample['class'] == True])\n",
    "# NearestNeighbors(n_neighbors=1)\n",
    "nn = neigh.kneighbors(data_sample[['loc','v(g)','class']].loc[data_sample['class'] == True])\n",
    "# (array([[0.5]]), array([[2]]))\n",
    "pd.DataFrame(nn[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  0  1  2\n",
       "1  1  2  0\n",
       "2  2  1  0\n",
       "3  3  0  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(nn[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAHlCAYAAADhgBXNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiBklEQVR4nO3df5TddX3n8ed7kokJc0d+BEjcpOxgk8pC0JAEBZmyhIho1vqjlh1Z2g01lu45nBUaPK2656y0i8fW9tClx7q7il10jWS6COJiFlGaiEGLJjEeAykmK0KTEH4kgncGSILz2T++N8kwzO/cmfv93Hk+zplz7/1+P9973++Ze/PK98f9fiOlhCRJyldLowuQJEnHxzCXJClzhrkkSZkzzCVJypxhLklS5gxzSZIyN73RBYzXqaeemjo6OkYc19vbS1tb28QXNMHso1zso3yapRf7KJcy9bFly5ZnU0qnDTYv2zDv6Ohg8+bNI47buHEjl1xyycQXNMHso1zso3yapRf7KJcy9RERjw81z83skiRlzjCXJClzhrkkSZnLdp+5NJUdPnyY3bt389JLLx3X85x44ons2LGjTlVNrJkzZzJ//nxaW1sbXYpUOoa5lKHdu3fT3t5OR0cHETHu56lWq7S3t9exsomRUmL//v3s3r2bM888s9HlSKXjZnYpQy+99BKzZ88+riDPSUQwe/bs494SITUrw1zK1FQJ8iOmWr/SWLiZXdK4TJs2jXPPPffo46997WsMdSKnSqVCT0/PJFUmTT2GuTQFVA9W6X64m537d7Jw9kK6zumi/TXHt6981qxZbNu2rT4FSjoubmaXmtymJzYx7+Z5XH/v9Xz6e5/m+nuvZ97N89j0xKa6vk5PTw8rVqxgyZIlnHvuudx9992vGvPkk09y8cUXs3jxYhYtWsR3v/tdAO677z4uvPBClixZwhVXXOFavDRGhrnUxKoHq6xcu5LqoSq9h3sB6D3cS/VQMb3n0PhD88UXX2Tx4sUsXryY973vfcycOZO77rqLrVu3smHDBm644QZSSq9Y5itf+QqXX34527Zt48c//jGLFy/m2Wef5aabbuLb3/42W7duZdmyZdx8883H1bc01biZXWpi3Q9305f6Bp3Xl/q489E7ufat147ruQduZj98+DAf//jHeeCBB2hpaWHPnj089dRTzJ079+iY888/nw9+8IMcPnyY9773vSxevJjvfOc7PPLII1x00UUAHDp0iAsvvHBcNUlTlWEuNbGd+3ceXSMfqPdwLz977md1e621a9fyzDPPsGXLFlpbW+no6HjVV8kuvvhiHnjgAb7xjW9w9dVXs2bNGk4++WQuu+wybr/99rrVIk01bmaXmtjC2Qtpax388o1trW28/qTX1+21nn/+eU4//XRaW1vZsGEDjz/+6gs8Pf7448yZM4c/+IM/4EMf+hBbt27lggsu4MEHH2TXrl1AccnJn/70p3WrS5oKXDOXmljXOV2s+eaaQee1RAu//YbfrttrXXXVVfzWb/0W5557LsuWLeOss8561ZiNGzfyl3/5l7S2tlKpVPjSl77Eaaedxm233caVV17JwYMHAbjpppv4jd/4jbrVJk2qahW6u2HnTli4ELq6YILPtGiYS02s/TXtrL9qPSvXrqQv9dF7uJe21jZaooX1V62nMqMy7uceeMT5qaeeyve///1hx65atYpVq1a9av6ll17KD3/4w3HXIpXGpk2wciX09UFvL7S1wZo1sH49dHZO2Msa5lKT6zyjk7037KV7eze7DuxiwSkL6FrURWVGhWq12ujypOZRrRZB3v9z1Vs7ZmXlSti7Fyrj/w/0cAxzaQqozKiwesnqRpchNbfu7mKNfDB9fcX81RPzOfQAOEmS6mHnzmNr4gP19kLtIM+JYJhLklQPCxcW+8gH09YGCxZM2Esb5pIk1UNXF7QMEastLcX8CWKYS5JUD+3txVHr7e3H1tDb2o5Nn6CD38AD4CSNw/79+1mxYgUA+/btY9q0aZx22mkA/OAHP2DGjBmNLE9qnM7O4qj17u5iH/mCBcUa+QQGORjm0tRQ55NYzJ49++h52W+88UYqlQof+chHjs5/+eWXmT7df140RVUqE3bU+lD8tEnNbriTWLzpTXV7mauvvpqZM2fyox/9iIsuuojXvva1rwj5RYsWcc8999DR0cGXv/xl/uZv/oZDhw7xlre8hc9+9rNMmzatbrVIU437zKVm1v8kFke+MtPbe2x6na8bvnv3br73ve8NewnTHTt20N3dzYMPPsi2bduYNm0aa9eurWsd0lTjmrnUzEY4iUXrnXfCteO7BOpgrrjiihHXsO+//362bNnC+eefDxTXRT/99NPrVoM0FRnmUjMb4SQW8bP6XQIVoK3fd2ynT59OX7//SBy5HGpKiVWrVvGpT32qrq8tTWVuZpea2QgnsUivr98lUAfq6Ohg69atAGzdupXHHnsMgBUrVnDHHXfw9NNPA3DgwIFBL5cqafQMc6mZjXASi8O/Xb9LoA70/ve/nwMHDnDOOefwmc985uglTc8++2xuuukm3v72t/PGN76Ryy67jCeffHLC6pCmAjezS83syMkqBh7N3tJSt5NY3HjjjYNOnzVrFvfdd9+g87q6uuiawLNhSVONYS41u+FOYuElUKWmYJhLU0EDTmIhafK4z1ySpMwZ5lKmUkqNLmFSTbV+pbEwzKUMzZw5k/3790+ZgEspsX//fmbOnNnoUqRScp+5lKH58+eze/dunnnmmeN6npdeeimbgJw5cybz589vdBlSKRnmUoZaW1s588wzj/t5Nm7cyHnnnVeHiiQ1kpvZJUnKnGEuSVLmDHNJkjJnmEuSlDnDXJKkzBnmkiRlzjCXJClzhrkkSZkzzCVJypxhLklS5gxzSZIyZ5hLkpQ5w1ySpMwZ5pIkZc4wlyQpc4a5JEmZm9Qwj4i/i4inI2J7v2mnRMS3ImJn7fbkyaxJkqTcTfaa+W3AOwZM+yhwf0ppIXB/7bEkSRqlSQ3zlNIDwIEBk98DfLF2/4vAeyezJkmSchcppcl9wYgO4J6U0qLa4+dSSifV7gfwiyOPB1n2GuAagDlz5ixdt27diK/X09NDpVKpS+2NZB/lYh/l0yy92Ee5lKmP5cuXb0kpLRt0ZkppUn+ADmB7v8fPDZj/i9E8z9KlS9NobNiwYVTjys4+ysU+yqdZerGPcilTH8DmNEQmluFo9qci4nUAtdunG1yPJElZKUOYfx1YVbu/Cri7gbVIkpSdyf5q2u3A94E3RMTuiFgN/DlwWUTsBN5WeyxJkkZp+mS+WErpyiFmrZjMOiRJaiZl2MwuSZKOg2EuSVLmDHNJkjJnmEuSlDnDXJKkzBnmkiRlzjCXJClzhrkkSZkzzCVJypxhLklS5gxzSZIyZ5hLkpQ5w1ySpMwZ5pIkZc4wlyQpc4a5JEmZM8wlScqcYS5JUuYMc0mSMmeYS5KUOcNckqTMGeaSJGXOMJckKXOGuSRJmTPMJUnKnGEuSVLmDHNJkjJnmEuSlDnDXJKkzBnmkiRlzjCXJClzhrkkSZkzzCVJypxhLklS5gxzSZIyZ5hLkpQ5w1ySpMwZ5pIkZc4wlyQpc4a5JEmZM8wlScqcYS5JUuYMc0mSMmeYS5KUOcNckqTMGeaSJGXOMJckKXOGuSRJmTPMJUnKnGEuSVLmDHNJkjJnmEuSlDnDXJKkzBnmkiRlzjCXJClzhrkkSZkzzCVJypxhLklS5gxzSZIyZ5hLkpQ5w1ySpMwZ5pIkZc4wlyQpc4a5JEmZM8wlScqcYS5JUuYMc0mSMmeYS5KUOcNckqTMGeaSJGWuNGEeEX8UEQ9HxPaIuD0iZja6JkmSclCKMI+IecCHgWUppUXANOADja1KkqQ8lCLMa6YDsyJiOnACsLfB9UiSlIVIKTW6BgAi4jrgk8CLwH0ppasGGXMNcA3AnDlzlq5bt27E5+3p6aFSqdS52slnH+ViH+XTLL3YR7mUqY/ly5dvSSktG3RmSqnhP8DJwD8ApwGtwNeA3x1umaVLl6bR2LBhw6jGlZ19lIt9lE+z9GIf5VKmPoDNaYhMLMtm9rcBj6WUnkkpHQbuBN7a4JokScpCWcL8CeCCiDghIgJYAexocE2SJGWhFGGeUnoIuAPYCvyEoq7PNbQoSZIyMb3RBRyRUvoE8IlG1yFJUm5KsWYuSZLGzzCXJClzhrkkSZkzzCVJypxhLklS5gxzSZIyZ5hLkpQ5w1ySpMwZ5pIkZc4wlyQpc4a5JEmZM8wlScqcYS5JUuYMc0mSMmeYS5KUOcNckqTMGeaSJGXOMJckKXOGuSRJmTPMJUnKnGEuSVLmDHNJkjJnmEuSlDnDXJKkzBnmkiRlzjCXJClzhrkkSZkzzCVJypxhLklS5gxzSZIyZ5hLkpQ5w1ySpMwZ5pIkZc4wlyQpc4a5JEmZM8wlScqcYS5JUuYMc0mSMmeYS5KUOcNckqTMGeaSJGXOMJckKXOGuSRJmTPMJUnKnGEuSVLmDHNJkjJnmEuSlDnDXJKkzBnmkiRlzjCXJClzhrkkSZkzzCVJypxhLklS5gxzSZIyZ5hLkpQ5w1ySpMwZ5pIkZc4wlyQpc4a5JEmZM8wlScqcYS5JUuYMc0mSMjd9tAMj4l8BbwPeDMwFZgIHgJ8Cm4D7UkovTkSRkiRpaMOumUfh30fED4GHgRuB+cBzwOPANOCdwFeBfRHxuYg4c0IrliRJrzDSmvmO2u3/An4vpfRPgw2KiBOAy4ErgJ9ExH9IKX25fmVKkqShjBTm/wm4M6WUhhuUUnoBuAu4KyLmU6y9S5KkSTBsmKeUvjrWJ0wp7QZ2j7siSZI0Jh7NLklS5sZyNPtjwFCb2/uAXwI/Bj6TUtpSh9okSdIojGXN/KsU4d8OPATcU7t9LdAKbAYuAP4xIi6vc52SpppqFW69Ff7kT4rbarXRFUmlNeo1c+Bpiu+Uvyul9NKRiRExC/g/wBPAIuDrwJ8C3xxLIRFxEnBr7TkS8MGU0vfH8hySmsSmTbByJfT1QW8vtLXBmjWwfj10dja6Oql0xrJm/mHg5v5BDlA7UcxfA9emlH4FfB44dxy13ALcm1I6C3gTx74WJ2kqqVaLIK9WiyCH4vbI9J6extYnldBYwvwkYM4Q8+YAldr954FfjaWIiDgRuBj4AkBK6VBK6bmxPIekJtHdXayRD6avr5gv6RVihK+QHxsYsQ5YAfwhcE9K6VBEzADeDfx34FsppSsj4sPA76eUzht1ERGLgc8Bj1CslW8Brksp9Q4Ydw1wDcCcOXOWrlu3bsTn7unpoVKpjDiu7OyjXOxjAu3ZA/v2DT1/7lyYN+9Vk0vZyzjYR7mUqY/ly5dvSSktG3RmSmlUPxRr5ndTHLn+K4pTuv6q9vhu4KTauN8B3jna560tswx4GXhL7fEtwH8ZbpmlS5em0diwYcOoxpWdfZSLfUygz38+pba2lODVP21tKd1666CLlbKXcbCPcilTH8DmNEQmjvoAuFRs9n5PRJxTC9+5wL7akz/cb9wdo33OfnYDu1NKD9Ue3wF8dBzPIyl3XV3FwW6DaWkp5kt6hbEczQ5ALbgfHnHg2J5zX0T8c0S8IaX0KMXm/Efq+RqSMtHeXhy1PvBo9paWYnpJNnlKZTJsmEfEb6aUvjuWJ6wdzHZGSuknY6zlPwJra/vhfwb8/hiXl9QsOjth797iYLddu2DBgmKN3CCXBjXSmnl37cxvXwDuSin9YqiBEXER8AHg94A/BsYU5imlbRSb7yWpCO7VqxtdhZSFkcL81ym+X/4J4H9ExE+B7cCzwEGKg+LOBM4DZgHrgbellDZPVMGSJOmVRrpq2ovAX0TEpyn2Y68AlgBnATOBA8CjwFeAr6eUnprYciVJ0kCjOgAupZQiog/4eO3weEmSVBJjOQPct4E9EXFLRLx1ogqSJEljM5YwP5fiQiiXA5si4vGI+KuI8KA1SZIaaNRhnlJ6OKX0n1NxIZQlFPvJ3wv8ICJ2RcRNE1SjJEkaxljWzI9KKW1LKX0spbSA4tzss4CP1bUySZI0KmM+AxxARJwMvB/oAv418CLFmrokSZpkow7ziHgt8D6KAF9BcWGUb1CcKGZ9GnCdc0mSNDnGsmb+DMUV0r4JXE3xvfLeYZeQJEkTbixhfg3wtZTS8xNVjCRJGruxXAL1ixNZiCRJGp9xHc0uSZLKwzCXJClzhrkkSZkzzCVJypxhLklS5gxzSZIyZ5hLkpQ5w1ySpMwZ5pIkZc4wlyQpc4a5JEmZM8wlScqcYS5JUuYMc0mSMmeYS5KUOcNckqTMGeaSJGXOMJckKXPTG12AJJVetQrd3bBzJyxcCF1d0N7e6KqkowxzSRrOpk2wciX09UFvL7S1wZo1sH49dHY2ujoJcDO7JA2tWi2CvFotghyK2yPTe3oaW59UY5hL0lC6u4s18sH09RXzpRIwzCVpKDt3HlsjH6i3F3btmtx6pCEY5pI0lIULi33kg2lrgwULJrceaQiGuSQNpasLWob4Z7KlpZgvlYBhLklDaW8vjlpvbz+2ht7Wdmx6pdLY+qQav5omScPp7IS9e4uD3XbtKjatd3UZ5CoVw1ySRlKpwOrVja5CGpKb2SVJypxhLklS5gxzSZIyZ5hLkpQ5w1ySpMwZ5pIkZc4wlyQpc4a5JEmZM8wlScqcYS5JUuYMc0mSMmeYS5KUOcNckqTMGeaSJGXOMJckKXOGuSRJmTPMJUnKnGEuSVLmDHNJkjJnmEuSlDnDXJKkzBnmkiRlzjCXJClzhrkkSZkzzCVJypxhLklS5gxzSZIyZ5hLkpQ5w1ySpMxNb3QBkkS1Ct3dsHMnLFwIXV3Q3t7oqqRslCrMI2IasBnYk1J6V6PrkTQJNm2ClSuhrw96e6GtDdasgfXrobOz0dVJWSjbZvbrgB2NLkLSJKlWiyCvVosgh+L2yPSensbWJ2WiNGEeEfOBfwPc2uhaJE2S7u5ijXwwfX3FfEkjipRSo2sAICLuAD4FtAMfGWwze0RcA1wDMGfOnKXr1q0b8Xl7enqoVCp1rnby2Ue52Eed7NkD+/YNPX/uXJg3b1RP1fBe6sQ+yqVMfSxfvnxLSmnZoDNTSg3/Ad4FfLZ2/xLgnpGWWbp0aRqNDRs2jGpc2dlHudhHnXz+8ym1taUEr/5pa0vp1ltH/VQN76VO7KNcytQHsDkNkYll2cx+EfDuiPg5sA64NCK+3NiSJE24ri5oGeKfoZaWYr6kEZUizFNKH0spzU8pdQAfAP4hpfS7DS5L0kRrby+OWm9vL45ih+L2yPSSbN6Uyq5UX02TNAV1dsLevcXBbrt2wYIFxRq5QS6NWunCPKW0EdjY4DIkTaZKBVavbnQVUrZKsZldkiSNn2EuSVLmDHNJkjJnmEuSlDnDXJKkzBnmkiRlzjCXJClzhrkkSZkzzCVJypxhLklS5gxzSZIyZ5hLkpQ5w1ySpMwZ5pIkZc4wlyQpc4a5JEmZM8wlScqcYS5JUuYMc0mSMmeYS5KUOcNckqTMGeaSJGXOMJckKXOGuSRJmTPMJUnKnGEuSVLmDHNJkjJnmEuSlDnDXJKkzBnmkiRlzjCXJClzhrkkSZkzzCVJypxhLklS5gxzSZIyZ5hLkpQ5w1ySpMwZ5pIkZc4wlyQpc4a5JEmZM8wlScqcYS5JUuYMc0mSMmeYS5KUOcNckqTMGeaSJGXOMJckKXOGuSRJmTPMJUnKnGEuSVLmDHNJkjJnmEuSlDnDXJKkzBnmkiRlzjCXJClzhrkkSZkzzCVJypxhLklS5gxzSZIyZ5hLkpQ5w1ySpMwZ5pIkZc4wlyQpc4a5JEmZM8wlScqcYS5JUuYMc0mSMmeYS5KUOcNckqTMTW90AZpc1YNVuh/uZuf+nSycvZCuc7pof037qMYB4152sHGSpPooRZhHxK8BXwLmAAn4XErplsZW1Xw2PbGJlWtX0pf66D3cS1trG2u+uYb1V62n84zOYcddd+91pJRoiZYxLzvYOElS/ZRlM/vLwA0ppbOBC4BrI+LsBtfUVKoHq6xcu5LqoSq9h3sB6D3cS/VQMb3nUM+w4144/AIvvvziuJYdOE6SVF+lCPOU0pMppa21+1VgBzCvsVU1l+6Hu+lLfYPO60t9dG/vHnHc8Szbf5wkqb4ipdToGl4hIjqAB4BFKaVfDph3DXANwJw5c5auW7duxOfr6emhUqlMQKWT63j72FPdw76efUPOn1uZy7z2eSOOO55l51bmcmKc6N+jRJqlD2ieXuyjXMrUx/Lly7eklJYNNq9UYR4RFeA7wCdTSncON3bZsmVp8+bNIz7nxo0bueSSS+pTYAMdbx+3br2V6++9/ujm7/7aWtu45R23sHrJ6mHHDWa0yx4Z9+u//HX/HiXSLH1A8/RiH+VSpj4iYsgwL8VmdoCIaAW+CqwdKcg1dl3ndNESg/+5W6KFrkVdI447nmX7j5Mk1VcpwjwiAvgCsCOldHOj62lG7a9pZ/1V62mf0U5baxtQrC23zyimV2ZUhh13QusJzJo+a1zLDhwnSaqvUnw1DbgI+D3gJxGxrTbt4yml9Y0rqfl0ntHJ3hv20r29m10HdrHglAV0Lep6VcgONQ4Y97IGuSRNnFKEeUppExCNrmMqqMyosHrJ6nGPO55lJUkToxSb2SVJ0vgZ5pIkZc4wlyQpc4a5JEmZM8wlScqcYS5JUuYMc0mSMmeYS5KUOcNckqTMGeaSJGXOMJckKXOGuSRJmTPMJUnKnGEuSVLmDHNJkjJnmEuSlDnDXJKkzBnmkiRlzjCXJClzhrkkSZkzzCVJypxhLklS5gxzSZIyZ5hLkpQ5w1ySpMwZ5pIkZc4wlyQpc4a5JEmZM8wlScqcYS5JUuamN7qARqserNL9cDc79+9k4eyFdJ3TRftr2kc1DhjVsmU32t9BvZeVJNXHlA7zTU9sYuXalfSlPnoP99LW2saab65h/VXr6Tyjc9hx1917HSklWqJl2GXLbrS/g3ovK0mqnym7mb16sMrKtSupHqrSe7gXgN7DvVQPFdN7DvUMO+6Fwy/w4ssvDrts2Y32d1DvZSVJ9TVlw7z74W76Ut+g8/pSH93bu0ccN9KyZTfa30G9l5Uk1deUDfOd+3ceXaMcqPdwL7sO7Bpx3EjLlt1ofwf1XlaSVF9TNswXzl5IW2vboPPaWttYcMqCEceNtGzZjfZ3UO9lJUn1NWXDvOucLlpi8PZbooWuRV0jjhtp2bIb7e+g3stKkupryoZ5+2vaWX/VetpntB9dw2xrbaN9RjG9MqMy7LgTWk9g1vRZwy5bdqP9HdR7WUlSfU3pr6Z1ntHJ3hv20r29m10HdrHglAV0Lep6VRANNQ4YcdmyG+3voN7LSpLqZ0qHOUBlRoXVS1aPe9xoli270f4O6r2sJKk+puxmdkmSmoVhLklS5gxzSZIyZ5hLkpQ5w1ySpMwZ5pIkZc4wlyQpc4a5JEmZM8wlScqcYS5JUuYMc0mSMmeYS5KUOcNckqTMGeaSJGUuUkqNrmFcIuIZ4PFRDD0VeHaCy5kM9lEu9lE+zdKLfZRLmfr4lyml0wabkW2Yj1ZEbE4pLWt0HcfLPsrFPsqnWXqxj3LJpQ83s0uSlDnDXJKkzE2FMP9cowuoE/soF/son2bpxT7KJYs+mn6fuSRJzW4qrJlLktTUmjrMI+IdEfFoROyKiI82up7Rioi/i4inI2J7v2mnRMS3ImJn7fbkRtY4GhHxaxGxISIeiYiHI+K62vSseomImRHxg4j4ca2PP61NPzMiHqq9v7ojYkajax2NiJgWET+KiHtqj7PrIyJ+HhE/iYhtEbG5Ni2r9xVARJwUEXdExD9FxI6IuDC3PiLiDbW/w5GfX0bE9bn1ARARf1T7jG+PiNtrn/0sPh9NG+YRMQ34W+CdwNnAlRFxdmOrGrXbgHcMmPZR4P6U0kLg/trjsnsZuCGldDZwAXBt7W+QWy8HgUtTSm8CFgPviIgLgL8A/jqltAD4BbC6cSWOyXXAjn6Pc+1jeUppcb+vDeX2vgK4Bbg3pXQW8CaKv0tWfaSUHq39HRYDS4EXgLvIrI+ImAd8GFiWUloETAM+QC6fj5RSU/4AFwLf7Pf4Y8DHGl3XGOrvALb3e/wo8Lra/dcBjza6xnH0dDdwWc69ACcAW4G3UJxIYnpt+iveb2X9AeZT/MN6KXAPEJn28XPg1AHTsnpfAScCj1E7dinXPgbU/nbgwRz7AOYB/wycAkyvfT4uz+Xz0bRr5hz7wxyxuzYtV3NSSk/W7u8D5jSymLGKiA7gPOAhMuyltml6G/A08C3g/wHPpZRerg3J5f31X4E/Bvpqj2eTZx8JuC8itkTENbVpub2vzgSeAf5nbbfHrRHRRn599PcB4Pba/az6SCntAf4KeAJ4Enge2EImn49mDvOmlYr/ImbzNYSIqABfBa5PKf2y/7xcekkp/SoVmxHnA28GzmpsRWMXEe8Cnk4pbWl0LXXQmVJaQrEb7dqIuLj/zEzeV9OBJcB/SymdB/QyYFN0Jn0AUNuX/G7gfw+cl0MftX3676H4T9a/ANp49e7O0mrmMN8D/Fq/x/Nr03L1VES8DqB2+3SD6xmViGilCPK1KaU7a5Oz7AUgpfQcsIFic9tJETG9NiuH99dFwLsj4ufAOopN7beQXx9H1qJIKT1NsX/2zeT3vtoN7E4pPVR7fAdFuOfWxxHvBLamlJ6qPc6tj7cBj6WUnkkpHQbupPjMZPH5aOYw/yGwsHYk4gyKzT9fb3BNx+PrwKra/VUU+59LLSIC+AKwI6V0c79ZWfUSEadFxEm1+7Mo9vvvoAj136kNK30fKaWPpZTmp5Q6KD4P/5BSuorM+oiItohoP3KfYj/tdjJ7X6WU9gH/HBFvqE1aATxCZn30cyXHNrFDfn08AVwQESfU/u068vfI4vPR1CeNiYiVFPsIpwF/l1L6ZGMrGp2IuB24hOJqPU8BnwC+Bvw9cAbF1eL+bUrpQINKHJWI6AS+C/yEY/toP06x3zybXiLijcAXKd5HLcDfp5T+LCJeT7GGewrwI+B3U0oHG1fp6EXEJcBHUkrvyq2PWr131R5OB76SUvpkRMwmo/cVQEQsBm4FZgA/A36f2nuMvPpoowjD16eUnq9Ny/Hv8adAF8U3cX4EfIhiH3npPx9NHeaSJE0FzbyZXZKkKcEwlyQpc4a5JEmZM8wlScqcYS5JUuYMc0lHRcRtR65CJikfhrkkSZkzzCVJypxhLmlIEbE4Iu6PiBci4hcRsTYi5gwYMysiPh0Rj0fEwYh4LCI+1aiapalo+shDJE1FEXEasJHiPPT/DqgAfw58KyKWpZQO1c5hfTfFhWf+C8UlI+cBv9mQoqUpyjCXNJQbareXH7l0bUTsBP4ReD/FRTXeTnHhmfeklPpfyOhLk1moNNW5mV3SUN4M3Nf/GvS1y3X+HOisTboUODAgyCVNMsNc0lBeR3HVvoGeoriCFMBs4MlJq0jSoAxzSUN5Ejh9kOlzgCOXstxPEfqSGsgwlzSUh4DLI6L9yISIOB/oADbVJt0PnBIR75r88iQd4fXMJR0VEbcBi1JKy2pHs+8EHgH+gmNHs/8C6H80+/8F3gr8GbCVYk394pTSHzagBWlKcs1c0qBSSs8Ay4GXKI5c/1vgu8BlKaVDtTEJeB/wOeB6imC/CXi2ASVLU5Zr5pIkZc41c0mSMmeYS5KUOcNckqTMGeaSJGXOMJckKXOGuSRJmTPMJUnKnGEuSVLmDHNJkjL3/wFpqHeP+nvJ/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# i += 1\n",
    "# print(i)\n",
    "# data_sample = data[['loc','v(g)','class']].sample(10,random_state=59)\n",
    "# data_sample = data.loc[[1013, 256, 6, 576, 773, 2104, 500, 131, 2100,211,1450]]\n",
    "import matplotlib.pyplot as plt\n",
    "principalDf = pd.DataFrame(data = data_sample, columns = ['loc', 'v(g)'])\n",
    "finalDf = pd.concat([principalDf, data_sample[['class']]], axis = 1)\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = plt.axes() \n",
    "ax.set_xlabel('loc', fontsize = 15)\n",
    "ax.set_ylabel('v(g)', fontsize = 15)\n",
    "# ax.set_zlabel('V3', fontsize = 15) \n",
    "# ax.set_title(i, fontsize = 20)\n",
    "targets = [False, True]\n",
    "colors = ['g', 'r','b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['class'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'loc'], finalDf.loc[indicesToKeep, 'v(g)'], c = color, s = 50)\n",
    "ax.legend(targets,loc=9)\n",
    "ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>55.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loc  v(g)  class\n",
       "1013   2.0   1.0  False\n",
       "256   55.0   5.0   True\n",
       "6     48.0   6.0   True\n",
       "576   15.0   1.0  False\n",
       "773    5.0   1.0  False\n",
       "2104  19.0   2.0  False\n",
       "500   17.0   2.0  False\n",
       "131   47.0   4.0   True\n",
       "2100  14.0   2.0  False\n",
       "1451   4.0   1.0  False\n",
       "1450  16.0   2.0  False\n",
       "1500  18.0   1.0  False\n",
       "2     83.0  11.0   True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample[['loc','v(g)','class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010000000000000009"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.3664914>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "bce = BinaryCrossentropy()\n",
    "bce([[0]],[[0.745]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(True, 4)])\n",
      "[[55.  5.  1.]\n",
      " [48.  6.  1.]\n",
      " [47.  4.  1.]\n",
      " [83. 11.  1.]]\n",
      "[[1 2]\n",
      " [2 0]\n",
      " [1 0]\n",
      " [0 1]]\n",
      "4\n",
      "[6 4 6 5]\n",
      "8\n",
      "step  [[0.49577329]\n",
      " [0.13382953]\n",
      " [0.14211109]\n",
      " [0.21855868]]\n",
      "Steps [[0.49577329]\n",
      " [0.13382953]\n",
      " [0.14211109]\n",
      " [0.21855868]]\n",
      "rows [3 2 3 2]\n",
      "cols [0 0 0 1]\n",
      "diffs [[-28.  -6.   0.]\n",
      " [  1.   2.   0.]\n",
      " [-28.  -6.   0.]\n",
      " [  8.   1.   0.]]\n",
      "nn_data [[55.  5.  1.]\n",
      " [48.  6.  1.]\n",
      " [47.  4.  1.]\n",
      " [83. 11.  1.]]\n",
      "nn_num [[1 2]\n",
      " [2 0]\n",
      " [1 0]\n",
      " [0 1]]\n",
      "nn_num row cols  [0 1 0 0]\n",
      "X row [[83. 11.  1.]\n",
      " [47.  4.  1.]\n",
      " [83. 11.  1.]\n",
      " [47.  4.  1.]]\n",
      "[[69.11834779  8.02536024  1.        ]\n",
      " [47.13382953  4.26765906  1.        ]\n",
      " [79.02088961 10.14733349  1.        ]\n",
      " [48.74846941  4.21855868  1.        ]]\n",
      "odict_items([(True, 4)])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sm = SMOTE(random_state=9, sampling_strategy=0.9, k_neighbors=2)\n",
    "X_train, y_train = sm.fit_sample(data_sample[['loc','v(g)','class']], data_sample['class'])\n",
    "# noise = np.random.normal(0,1,[len(X_train),2])\n",
    "# X_train[['loc','v(g)']] = X_train[['loc','v(g)']] + noise\n",
    "principalDf = pd.DataFrame(data = X_train, columns = ['loc', 'v(g)'])\n",
    "finalDf = pd.concat([principalDf, X_train[['class']]], axis = 1)\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = plt.axes() \n",
    "ax.set_xlabel('loc', fontsize = 15)\n",
    "ax.set_ylabel('v(g)', fontsize = 15)\n",
    "# ax.set_zlabel('V3', fontsize = 15) \n",
    "# ax.set_title(i, fontsize = 20)\n",
    "targets = [False, True]\n",
    "colors = ['g', 'r','b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['class'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'loc'], finalDf.loc[indicesToKeep, 'v(g)'], c = color, s = 50)\n",
    "\n",
    "targets = [False, True, \"Syntethic Instance\"]\n",
    "ax.scatter(X_train[X_train.index >= len(data_sample)]['loc'], X_train[X_train.index >= len(data_sample)]['v(g)'], c = 'm', s = 50)\n",
    "ax.legend(targets,loc=9)\n",
    "ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix    #Confussion Matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "\n",
    "def gmeans(y_true, Y_pred):\n",
    "    # repro()\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, Y_pred, labels=[0,1]).ravel()\n",
    "    pf = fp/(fp+tn)\n",
    "    pd = tp/(tp+fn)\n",
    "    gmeans = math.sqrt(pd*(1-pf))\n",
    "    return gmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "56/56 [==============================] - 0s 946us/step - loss: 0.0148 - accuracy: 0.5177\n",
      "Epoch 2/100\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.0059 - accuracy: 0.6862\n",
      "Epoch 3/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.7605\n",
      "Epoch 4/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 0.7785\n",
      "Epoch 5/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.7872\n",
      "Epoch 6/100\n",
      "56/56 [==============================] - 0s 1000us/step - loss: 0.0028 - accuracy: 0.7832\n",
      "Epoch 7/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.7877\n",
      "Epoch 8/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.7790\n",
      "Epoch 9/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.7824\n",
      "Epoch 10/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 0.7768\n",
      "Epoch 11/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 0.7787\n",
      "Epoch 12/100\n",
      "56/56 [==============================] - 0s 1000us/step - loss: 0.0027 - accuracy: 0.7762\n",
      "Epoch 13/100\n",
      "56/56 [==============================] - 0s 910us/step - loss: 0.0025 - accuracy: 0.7888\n",
      "Epoch 14/100\n",
      "56/56 [==============================] - 0s 893us/step - loss: 0.0022 - accuracy: 0.8001\n",
      "Epoch 15/100\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.0021 - accuracy: 0.8071\n",
      "Epoch 16/100\n",
      "56/56 [==============================] - 0s 910us/step - loss: 0.0020 - accuracy: 0.8102\n",
      "Epoch 17/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.8158\n",
      "Epoch 18/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.8124\n",
      "Epoch 19/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 0.8166\n",
      "Epoch 20/100\n",
      "56/56 [==============================] - 0s 964us/step - loss: 0.0020 - accuracy: 0.8158\n",
      "Epoch 21/100\n",
      "56/56 [==============================] - 0s 946us/step - loss: 0.0020 - accuracy: 0.8132\n",
      "Epoch 22/100\n",
      "56/56 [==============================] - 0s 892us/step - loss: 0.0020 - accuracy: 0.8158\n",
      "Epoch 23/100\n",
      "56/56 [==============================] - 0s 946us/step - loss: 0.0020 - accuracy: 0.8144\n",
      "Epoch 24/100\n",
      "56/56 [==============================] - 0s 857us/step - loss: 0.0020 - accuracy: 0.8102\n",
      "Epoch 25/100\n",
      "56/56 [==============================] - 0s 886us/step - loss: 0.0020 - accuracy: 0.8146\n",
      "Epoch 26/100\n",
      "56/56 [==============================] - 0s 892us/step - loss: 0.0020 - accuracy: 0.8172\n",
      "Epoch 27/100\n",
      "56/56 [==============================] - 0s 946us/step - loss: 0.0020 - accuracy: 0.8191\n",
      "Epoch 28/100\n",
      "56/56 [==============================] - 0s 1000us/step - loss: 0.0020 - accuracy: 0.8093\n",
      "Epoch 29/100\n",
      "56/56 [==============================] - 0s 946us/step - loss: 0.0020 - accuracy: 0.8096\n",
      "Epoch 30/100\n",
      "56/56 [==============================] - 0s 946us/step - loss: 0.0020 - accuracy: 0.8135\n",
      "Epoch 31/100\n",
      "56/56 [==============================] - 0s 857us/step - loss: 0.0019 - accuracy: 0.8169\n",
      "Epoch 32/100\n",
      "56/56 [==============================] - 0s 857us/step - loss: 0.0019 - accuracy: 0.8183\n",
      "Epoch 33/100\n",
      "56/56 [==============================] - 0s 964us/step - loss: 0.0019 - accuracy: 0.8163\n",
      "Epoch 34/100\n",
      "56/56 [==============================] - 0s 875us/step - loss: 0.0019 - accuracy: 0.8144\n",
      "Epoch 35/100\n",
      "56/56 [==============================] - 0s 1000us/step - loss: 0.0019 - accuracy: 0.8163\n",
      "Epoch 36/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.8188\n",
      "Epoch 37/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.8163\n",
      "Epoch 38/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 0.8172\n",
      "Epoch 39/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.8135\n",
      "Epoch 40/100\n",
      "56/56 [==============================] - 0s 946us/step - loss: 0.0018 - accuracy: 0.8177\n",
      "Epoch 41/100\n",
      "56/56 [==============================] - 0s 964us/step - loss: 0.0018 - accuracy: 0.8169\n",
      "Epoch 42/100\n",
      "56/56 [==============================] - 0s 893us/step - loss: 0.0018 - accuracy: 0.8158\n",
      "Epoch 43/100\n",
      "56/56 [==============================] - 0s 857us/step - loss: 0.0018 - accuracy: 0.8152\n",
      "Epoch 44/100\n",
      "56/56 [==============================] - 0s 929us/step - loss: 0.0018 - accuracy: 0.8110\n",
      "Epoch 45/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.8160\n",
      "Epoch 46/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.8183\n",
      "Epoch 47/100\n",
      "56/56 [==============================] - 0s 892us/step - loss: 0.0018 - accuracy: 0.8160\n",
      "Epoch 48/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.8146\n",
      "Epoch 49/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.8160\n",
      "Epoch 50/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.8188\n",
      "Epoch 51/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.8163\n",
      "Epoch 52/100\n",
      "56/56 [==============================] - 0s 999us/step - loss: 0.0018 - accuracy: 0.8146\n",
      "Epoch 53/100\n",
      "56/56 [==============================] - 0s 857us/step - loss: 0.0018 - accuracy: 0.8158\n",
      "Epoch 54/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.8160\n",
      "Epoch 55/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.8160\n",
      "Epoch 56/100\n",
      "56/56 [==============================] - 0s 999us/step - loss: 0.0018 - accuracy: 0.8177\n",
      "Epoch 57/100\n",
      "56/56 [==============================] - 0s 910us/step - loss: 0.0018 - accuracy: 0.8149\n",
      "Epoch 58/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.8138\n",
      "Epoch 59/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.8172\n",
      "Epoch 60/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.8183\n",
      "Epoch 61/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.8172\n",
      "Epoch 62/100\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.0018 - accuracy: 0.8160\n",
      "Epoch 63/100\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.0017 - accuracy: 0.8180\n",
      "Epoch 64/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.8211\n",
      "Epoch 65/100\n",
      "56/56 [==============================] - 0s 892us/step - loss: 0.0018 - accuracy: 0.8205\n",
      "Epoch 66/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.8216\n",
      "Epoch 67/100\n",
      "56/56 [==============================] - 0s 999us/step - loss: 0.0018 - accuracy: 0.8172\n",
      "Epoch 68/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.8166\n",
      "Epoch 69/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 0.8180\n",
      "Epoch 70/100\n",
      "56/56 [==============================] - 0s 999us/step - loss: 0.0018 - accuracy: 0.8183\n",
      "Epoch 71/100\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.0018 - accuracy: 0.8155\n",
      "Epoch 72/100\n",
      "56/56 [==============================] - 0s 892us/step - loss: 0.0018 - accuracy: 0.8188\n",
      "Epoch 73/100\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.0017 - accuracy: 0.8152\n",
      "Epoch 74/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.8155\n",
      "Epoch 75/100\n",
      "56/56 [==============================] - 0s 928us/step - loss: 0.0017 - accuracy: 0.8180\n",
      "Epoch 76/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.8163\n",
      "Epoch 77/100\n",
      "56/56 [==============================] - 0s 892us/step - loss: 0.0017 - accuracy: 0.8172\n",
      "Epoch 78/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.8180\n",
      "Epoch 79/100\n",
      "56/56 [==============================] - 0s 964us/step - loss: 0.0017 - accuracy: 0.8197\n",
      "Epoch 80/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.8169\n",
      "Epoch 81/100\n",
      "56/56 [==============================] - 0s 946us/step - loss: 0.0017 - accuracy: 0.8186\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.8202\n",
      "Epoch 83/100\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.0017 - accuracy: 0.8177\n",
      "Epoch 84/100\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.0017 - accuracy: 0.8172\n",
      "Epoch 85/100\n",
      "56/56 [==============================] - 0s 999us/step - loss: 0.0017 - accuracy: 0.8194\n",
      "Epoch 86/100\n",
      "56/56 [==============================] - 0s 999us/step - loss: 0.0017 - accuracy: 0.8160\n",
      "Epoch 87/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 0.8219\n",
      "Epoch 88/100\n",
      "56/56 [==============================] - 0s 994us/step - loss: 0.0017 - accuracy: 0.8197\n",
      "Epoch 89/100\n",
      "56/56 [==============================] - 0s 946us/step - loss: 0.0016 - accuracy: 0.8172\n",
      "Epoch 90/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.8216\n",
      "Epoch 91/100\n",
      "56/56 [==============================] - 0s 910us/step - loss: 0.0016 - accuracy: 0.8245\n",
      "Epoch 92/100\n",
      "56/56 [==============================] - 0s 999us/step - loss: 0.0016 - accuracy: 0.8194\n",
      "Epoch 93/100\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.0016 - accuracy: 0.8242\n",
      "Epoch 94/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.8231\n",
      "Epoch 95/100\n",
      "56/56 [==============================] - 0s 946us/step - loss: 0.0016 - accuracy: 0.8247\n",
      "Epoch 96/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.8278\n",
      "Epoch 97/100\n",
      "56/56 [==============================] - 0s 892us/step - loss: 0.0016 - accuracy: 0.8301\n",
      "Epoch 98/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 0.8315\n",
      "Epoch 99/100\n",
      "56/56 [==============================] - 0s 928us/step - loss: 0.0016 - accuracy: 0.8242\n",
      "Epoch 100/100\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 0.8256\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential       \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras\n",
    "from imblearn.over_sampling import SMOTE\n",
    "tensorflow.keras.backend.set_floatx('float64')\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaller = MinMaxScaler()\n",
    "\n",
    "X_train = scaller.fit_transform(data_sample.iloc[:,data_sample.columns != 'class'])\n",
    "opt = optimizers.Adam(learning_rate=0.005)\n",
    "model = Sequential()\n",
    "# model.add(Dense(, activation='relu', kernel_initializer=tensorflow.keras.initializers.glorot_uniform(seed=42)))\n",
    "\n",
    "# input = Input(21)\n",
    "model.add(Dense(21 ,activation='sigmoid', kernel_initializer=tensorflow.keras.initializers.glorot_uniform(seed=42)));\n",
    "model.add(Dense(15 ,activation='sigmoid', kernel_initializer=tensorflow.keras.initializers.glorot_uniform(seed=42)));\n",
    "model.add(Dense(10 ,activation='sigmoid', kernel_initializer=tensorflow.keras.initializers.glorot_uniform(seed=42)));\n",
    "model.add(Dense(5 ,activation='sigmoid', kernel_initializer=tensorflow.keras.initializers.glorot_uniform(seed=42)));\n",
    "# model.add(Dense(1 ,activation='sigmoid', kernel_initializer=tensorflow.keras.initializers.glorot_uniform(seed=42)));\n",
    "# model.add(Dense(5 ,activation='linear', kernel_initializer=tensorflow.keras.initializers.glorot_uniform(seed=42)));\n",
    "model.add(Dense(10 ,activation='linear', kernel_initializer=tensorflow.keras.initializers.glorot_uniform(seed=42)));\n",
    "model.add(Dense(15 ,activation='linear', kernel_initializer=tensorflow.keras.initializers.glorot_uniform(seed=42)));\n",
    "model.add(Dense(21, activation='linear', kernel_initializer=tensorflow.keras.initializers.glorot_uniform(seed=42)));\n",
    "\n",
    "#     model.add(Dropout(drop))\n",
    "# model.add(Dense(21, activation='sigmoid'))\n",
    "model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "sm = SMOTE(random_state=9, sampling_strategy=1, k_neighbors=5)\n",
    "X_train, y_train = sm.fit_sample(X_train, data_sample['class'])\n",
    "X_train_pure = X_train.copy()\n",
    "\n",
    "noise = np.random.normal(0,1,[len(X_train),21])\n",
    "X_train_noise = X_train + noise * 0.05\n",
    "\n",
    "model.fit(X_train_noise, X_train_pure, epochs = 100, batch_size = 64, verbose = 1)\n",
    "test = model.predict(X_train)\n",
    "# model.summary()\n",
    "# result = gmeans(y_dev_true_collect, y_dev_pred_collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7772844568282088"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "# depth = int()\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "score = make_scorer(gmeans)\n",
    "\n",
    "\n",
    "cv_results = cross_validate(dt, test, y_train, cv=10, scoring=score)\n",
    "cv_results['test_score'].mean()\n",
    "# result = gmeans(y_train, y_pred)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8468302266909727"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = cross_validate(dt, X_train, y_train, cv=10, scoring=score)\n",
    "cv_results['test_score'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
